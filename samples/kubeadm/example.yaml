apiVersion: v1
kind: Namespace
metadata:
  name: ${CLUSTER_NAMESPACE}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster 
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: ${CLUSTER_NAME} 
  labels:
    ccm: external
    csi: external
    cni: external
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - ${POD_CIDR}
    services:
      cidrBlocks:
      - ${SERVICE_CIDR}
    serviceDomain: cluster.local
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: ${CLUSTER_NAME}-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
    kind: HarvesterCluster
    name: ${CLUSTER_NAME}-hv
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: HarvesterCluster
metadata:
  name: ${CLUSTER_NAME}-hv
  namespace: ${CLUSTER_NAMESPACE}
spec:
  targetNamespace: default
  loadBalancerConfig:
    ipamType: dhcp
  server: ${HARVESTER_ENDPOINT} 
  identitySecret: 
    namespace: ${CLUSTER_NAMESPACE}
    name: hv-identity-secret
---
apiVersion: v1
kind: Secret
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: hv-identity-secret
data: 
  kubeconfig: ${HARVESTER_KUBECONFIG_B64}
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: ${CLUSTER_NAME}-control-plane
spec:
  replicas: ${CONTROLPLANE_REPLICAS}
  kubeadmConfigSpec: 
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          cloud-provider: external 
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          cloud-provider: external
    postKubeadmCommands:
    - sudo kubectl --kubeconfig /etc/kubernetes/admin.conf create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.4/manifests/tigera-operator.yaml
    - curl -s https://raw.githubusercontent.com/projectcalico/calico/v3.26.4/manifests/custom-resources.yaml | sed -e 's|192\.168\.0\.0/16|${POD_CIDR}|g' | sudo kubectl --kubeconfig /etc/kubernetes/admin.conf apply -f - 
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
      kind: HarvesterMachineTemplate
      name: ${CLUSTER_NAME}-cp-machine
      namespace: ${CLUSTER_NAMESPACE}
  version: v1.26.6 
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: ${CLUSTER_NAME}-worker
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            cloud-provider: external
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: ${CLUSTER_NAME}-workers
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WORKER_REPLICAS}
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: ${CLUSTER_NAME}-worker
          namespace: ${CLUSTER_NAMESPACE}
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
        kind: HarvesterMachineTemplate
        name: ${CLUSTER_NAME}-wk-machine
        namespace: ${CLUSTER_NAMESPACE}
      version: v1.26.6
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: HarvesterMachineTemplate
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: ${CLUSTER_NAME}-wk-machine
spec:
  template: 
    spec:
      cpu: 1
      memory: 4Gi
      sshUser: ubuntu
      sshKeyPair: ${SSH_KEYPAIR}  
      networks:
      - default/untagged
      volumes:
      - volumeType: image 
        imageName: ${VM_IMAGE_NAME}
        volumeSize: 50Gi
        bootOrder: 0
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: HarvesterMachineTemplate
metadata:
  namespace: ${CLUSTER_NAMESPACE}
  name: ${CLUSTER_NAME}-cp-machine
spec:
  template: 
    spec:
      cpu: 2
      memory: 8Gi
      sshUser: ubuntu
      sshKeyPair: ${SSH_KEYPAIR}  
      networks:
      - default/untagged
      volumes:
      - volumeType: image 
        imageName: ${VM_IMAGE_NAME}
        volumeSize: 50Gi
        bootOrder: 0
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: crs-harvester-ccm
  namespace: ${CLUSTER_NAMESPACE}
spec:
  clusterSelector:
    matchLabels:
      ccm: external
  resources:
  - kind: ConfigMap
    name: cloud-controller-manager-addon
  strategy: ApplyOnce
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: crs-harvester-csi
  namespace: ${CLUSTER_NAMESPACE}
spec:
  clusterSelector:
    matchLabels:
      csi: external
  resources:
  - kind: ConfigMap
    name: harvester-csi-driver-addon
  strategy: ApplyOnce
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cloud-controller-manager-addon
  namespace: ${CLUSTER_NAMESPACE}
data:
  harvester-csi-deployment.yaml: |
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: harvester-csi-plugin
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          app: harvester-csi-plugin
      template:
        metadata:
          labels:
            app: harvester-csi-plugin
        spec:
          containers:
            - args:
                - --v=5
                - --csi-address=$(ADDRESS)
                - --kubelet-registration-path=/var/lib/kubelet/harvester-plugins/driver.harvesterhci.io/csi.sock
              env:
                - name: ADDRESS
                  value: /csi/csi.sock
              image: longhornio/csi-node-driver-registrar:v1.2.0-lh1
              lifecycle:
                preStop:
                  exec:
                    command:
                      - /bin/sh
                      - -c
                      - rm -rf /registration/driver.harvesterhci.io-reg.sock
                        /csi//*
              name: node-driver-registrar
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /csi/
                  name: socket-dir
                - mountPath: /registration
                  name: registration-dir
            - args:
                - --nodeid=$(NODE_ID)
                - --endpoint=$(CSI_ENDPOINT)
                - --kubeconfig=/etc/csi/cloud-config
              env:
                - name: NODE_ID
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: spec.nodeName
                - name: CSI_ENDPOINT
                  value: unix:///csi/csi.sock
              image: rancher/harvester-csi-driver:v0.1.6
              imagePullPolicy: Always
              lifecycle:
                preStop:
                  exec:
                    command:
                      - /bin/sh
                      - -c
                      - rm -f /csi//*
              name: harvester-csi-plugin
              securityContext:
                allowPrivilegeEscalation: true
                capabilities:
                  add:
                    - SYS_ADMIN
                privileged: true
              volumeMounts:
                - name: cloud-config
                  mountPath: "/etc/csi"
                  readOnly: true
                - mountPath: /var/lib/kubelet/plugins/kubernetes.io/csi
                  mountPropagation: Bidirectional
                  name: kubernetes-csi-dir
                - mountPath: /csi/
                  name: socket-dir
                - mountPath: /var/lib/kubelet/pods
                  mountPropagation: Bidirectional
                  name: pods-mount-dir
                - mountPath: /dev
                  name: host-dev
                - mountPath: /sys
                  name: host-sys
                - mountPath: /rootfs
                  mountPropagation: Bidirectional
                  name: host
                - mountPath: /lib/modules
                  name: lib-modules
                  readOnly: true
          hostPID: true
          serviceAccountName: harvester-csi
          tolerations:
            - effect: NoSchedule
              key: node-role.kubernetes.io/control-plane
              operator: Exists
            - effect: NoSchedule
              key: kubevirt.io/drain
              operator: Exists
          volumes:
            - name: cloud-config
              secret:
                secretName: cloud-config
            - hostPath:
                path: /var/lib/kubelet/plugins/kubernetes.io/csi
                type: DirectoryOrCreate
              name: kubernetes-csi-dir
            - hostPath:
                path: /var/lib/kubelet/plugins_registry
                type: Directory
              name: registration-dir
            - hostPath:
                path: /var/lib/kubelet/harvester-plugins/driver.harvesterhci.io
                type: DirectoryOrCreate
              name: socket-dir
            - hostPath:
                path: /var/lib/kubelet/pods
                type: DirectoryOrCreate
              name: pods-mount-dir
            - hostPath:
                path: /dev
              name: host-dev
            - hostPath:
                path: /sys
              name: host-sys
            - hostPath:
                path: /
              name: host
            - hostPath:
                path: /lib/modules
              name: lib-modules
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: harvester-csi
      namespace: kube-system
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: harvester-csi
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: cluster-admin
    subjects:
      - kind: ServiceAccount
        name: harvester-csi
        namespace: kube-system
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: csi-controller
      namespace: kube-system
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: csi-controller
      template:
        metadata:
          labels:
            app: csi-controller
        spec:
          containers:
            - args:
                - --v=5
                - --csi-address=$(ADDRESS)
                - --csiTimeout=2m5s
                - --leader-election
                - --leader-election-namespace=$(POD_NAMESPACE)
              env:
                - name: ADDRESS
                  value: /csi/csi.sock
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.namespace
              image: longhornio/csi-resizer:v0.5.1-lh1
              name: csi-resizer
              volumeMounts:
                - mountPath: /csi/
                  name: socket-dir
            - args:
                - --v=5
                - --csi-address=$(ADDRESS)
                - --timeout=2m5s
                - --enable-leader-election
                - --leader-election-type=leases
                - --leader-election-namespace=$(POD_NAMESPACE)
              env:
                - name: ADDRESS
                  value: /csi/csi.sock
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.namespace
              image: longhornio/csi-provisioner:v1.6.0-lh1
              name: csi-provisioner
              volumeMounts:
                - mountPath: /csi/
                  name: socket-dir
            - args:
                - --v=5
                - --csi-address=$(ADDRESS)
                - --timeout=2m5s
                - --leader-election
                - --leader-election-namespace=$(POD_NAMESPACE)
              env:
                - name: ADDRESS
                  value: /csi/csi.sock
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.namespace
              image: longhornio/csi-attacher:v2.2.1-lh1
              name: csi-attacher
              volumeMounts:
                - mountPath: /csi/
                  name: socket-dir
          serviceAccountName: harvester-csi
          tolerations:
            - effect: NoSchedule
              key: node-role.kubernetes.io/control-plane
              operator: Exists
            - effect: NoSchedule
              key: kubevirt.io/drain
              operator: Exists
          volumes:
            - hostPath:
                path: /var/lib/kubelet/harvester-plugins/driver.harvesterhci.io
                type: DirectoryOrCreate
              name: socket-dir
    ---
    apiVersion: storage.k8s.io/v1
    kind: CSIDriver
    metadata:
      name: driver.harvesterhci.io
    spec:
      attachRequired: true
      fsGroupPolicy: ReadWriteOnceWithFSType
      podInfoOnMount: true
      volumeLifecycleModes:
        - Persistent
    ---
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: harvester
    allowVolumeExpansion: true
    provisioner: driver.harvesterhci.io
    reclaimPolicy: Delete
    volumeBindingMode: Immediate
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: harvester-csi-driver-addon
  namespace: ${CLUSTER_NAMESPACE}
data:
  harvester-cloud-provider-deploy.yaml: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app.kubernetes.io/component: cloud-provider
        app.kubernetes.io/name: harvester-cloud-provider
      name: harvester-cloud-provider
      namespace: kube-system
    spec:
      replicas: 2
      selector:
        matchLabels:
          app.kubernetes.io/component: cloud-provider
          app.kubernetes.io/name: harvester-cloud-provider
      template:
        metadata:
          labels:
            app.kubernetes.io/component: cloud-provider
            app.kubernetes.io/name: harvester-cloud-provider
        spec:
          containers:
          - args:
            - --cloud-config=/etc/kubernetes/cloud-config
            command:
            - harvester-cloud-provider
            image: rancher/harvester-cloud-provider:v0.2.0
            imagePullPolicy: Always
            name: harvester-cloud-provider
            resources: {}
            volumeMounts:
            - mountPath: /etc/kubernetes
              name: cloud-config
          serviceAccountName: harvester-cloud-controller-manager
          tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/control-plane
            operator: Exists
          - effect: NoSchedule
            key: node.cloudprovider.kubernetes.io/uninitialized
            operator: Equal
            value: "true"
          volumes:
            - name: cloud-config
              secret:
                secretName: cloud-config
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: harvester-cloud-controller-manager
      namespace: kube-system
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: harvester-cloud-controller-manager
    rules:
    - apiGroups:
      - ""
      resources:
      - services
      - nodes
      - events
      verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
    - apiGroups:
      - ""
      resources:
      - services/status
      verbs:
      - update
      - patch
    - apiGroups:
      - ""
      resources:
      - nodes/status
      verbs:
      - patch
      - update
    - apiGroups:
      - coordination.k8s.io
      resources:
      - leases
      verbs:
      - get
      - create
      - update
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: harvester-cloud-controller-manager
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: harvester-cloud-controller-manager
    subjects:
      - kind: ServiceAccount
        name: harvester-cloud-controller-manager
        namespace: kube-system
    ---
    apiVersion: v1
    kind: Secret
    metadata:
      name: cloud-config
      namespace: kube-system
    type: Opaque
    data:
      cloud-config: ${HARVESTER_KUBECONFIG_B64}